{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b0d0b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"energy_consumption_queries.csv\")\n",
    "\n",
    "df.to_excel(\"energy_temp.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2a36b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\scerda\\Documents\\langgraph-postgres-energy-data\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from agent.configuration import Configuration\n",
    "from agent.utils import load_chat_model\n",
    "import pandas as pd\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab62ac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_chat_model(\"ollama/gemma3-v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d6c2b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent.state import QueryOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fc0b5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=model.invoke(\"\"\"You are a powerful text-to-SQL model. Your job is to answer questions about a database. You are given a question and context regarding one or more tables.\n",
    "You must output the postgres SQL query that answers the question\n",
    "\n",
    "DATABASE SCHEMA:\n",
    "CREATE TABLE smart_buildings.building ( cups TEXT PRIMARY KEY, name TEXT NOT NULL, address TEXT, type TEXT );\n",
    "CREATE TABLE smart_buildings.energy_consumption_monthly_metrics ( cups TEXT NOT NULL, year_month DATE NOT NULL, total_consumption_kwh DOUBLE PRECISION, avg_daily_consumption_kwh DOUBLE PRECISION, total_consumption_prev_month_kwh DOUBLE PRECISION, diff_pct_consumption_prev_month DOUBLE PRECISION, std_daily_consumption_kwh DOUBLE PRECISION, ytd_consumption_kwh NUMERIC, ytd_prev_year_consumption_kwh NUMERIC, total_consumption_prev_year_same_month_kwh NUMERIC, date_insert TIMESTAMP DEFAULT CURRENT_TIMESTAMP, PRIMARY KEY (cups, year_month), FOREIGN KEY (cups) REFERENCES smart_buildings.building(cups) );\n",
    "CREATE TABLE smart_buildings.energy_consumption_weekly_metrics ( cups TEXT NOT NULL, week_start DATE NOT NULL, total_consumption_kwh DOUBLE PRECISION, daily_consumption_kwh DOUBLE PRECISION, total_consumption_prev_week_kwh DOUBLE PRECISION, diff_pct_consumption_prev_week DOUBLE PRECISION, std_daily_consumption_kwh DOUBLE PRECISION, date_insert TIMESTAMP DEFAULT CURRENT_TIMESTAMP, PRIMARY KEY (cups, week_start), FOREIGN KEY (cups) REFERENCES smart_buildings.building(cups) );\n",
    "\n",
    "Some example building names that might be useful for the query:\n",
    "['Línea De Socorro Ceip Federico García Lorca', 'La Torre']\n",
    "\n",
    "Building types:\n",
    "['Administración', 'Educación', 'Comercio', 'Punto Limpio', 'Casal/Centro Cívico', 'Cultura y Ocio', 'Restauración', 'Salud y Servicios Sociales', 'Bienestar Social', 'Mercado', 'Parque', 'Industrial', 'Centros Deportivos', 'Parking', 'Policia', 'Cementerio', 'Protección Civil']\n",
    "\n",
    "CURRENT DATE: 2025-05-21\n",
    "                                                                                                                    \n",
    "Return **only** the SQL query—no additional explanation or formatting.\n",
    "             \n",
    "¿Podrías darme un resumen del consumo anual del edificio 'Torre Alta'?\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f76003f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT b.name AS building_name,\n",
      "       EXTRACT(YEAR\n",
      "               FROM e.year_month) AS YEAR,\n",
      "       SUM(e.total_consumption_kwh) AS total_consumption_kwh,\n",
      "       ROUND(AVG(e.total_consumption_kwh), 2) AS avg_monthly_consumption_kwh\n",
      "FROM smart_buildings.building b\n",
      "JOIN smart_buildings.energy_consumption_monthly_metrics e ON b.cups = e.cups\n",
      "WHERE b.name = 'La Torre'\n",
      "  AND EXTRACT(YEAR\n",
      "              FROM e.year_month) = EXTRACT(YEAR\n",
      "                                           FROM CURRENT_DATE)\n",
      "GROUP BY b.name,\n",
      "         EXTRACT(YEAR\n",
      "                 FROM e.year_month);\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0ad200c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT b.name AS building_name, \n",
      " m.year_month, \n",
      " m.total_consumption_kwh, \n",
      " m.avg_daily_consumption_kwh, \n",
      " m.total_consumption_prev_month_kwh, \n",
      " m.diff_pct_consumption_prev_month, \n",
      " m.std_daily_consumption_kwh, \n",
      " m.ytd_consumption_kwh \n",
      "FROM smart_buildings.building b \n",
      "JOIN smart_buildings.energy_consumption_monthly_metrics m ON b.cups = m.cups \n",
      "WHERE b.name = 'Torres Norte' \n",
      "AND EXTRACT(YEAR  FROM m.year_month) = EXTRACT(YEAR FROM CURRENT_DATE) \n",
      "ORDER BY m.year_month DESC \n",
      "LIMIT 1;\n"
     ]
    }
   ],
   "source": [
    "print(response.query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e49d160b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado como training_v2.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlparse\n",
    "\n",
    "# Parámetros de entrada\n",
    "excel_file = 'training.csv'\n",
    "\n",
    "# Lee el Excel\n",
    "df = pd.read_csv(excel_file,encoding='latin1',sep=\";\")\n",
    "\n",
    "def pretty_sql(sql_text):\n",
    "    if pd.isnull(sql_text):\n",
    "        return sql_text\n",
    "    return sqlparse.format(sql_text, reindent=True, keyword_case='upper')\n",
    "\n",
    "# Aplica el formateo a la columna 'sql'\n",
    "df['sql_parsed'] = df['sql'].apply(pretty_sql)\n",
    "df.sql_parsed = df.sql_parsed.str.replace('\"','')\n",
    "df.sql_parsed = \"```sql\\n\"+df.sql_parsed+\"\\n```\"\n",
    "# Guarda el resultado en un nuevo archivo\n",
    "output_file = 'training_v2.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Archivo guardado como {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccea969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT b.name AS building_name,\n",
      "       EXTRACT(YEAR\n",
      "               FROM e.year_month) AS YEAR,\n",
      "       SUM(e.total_consumption_kwh) AS total_consumption_kwh_year,\n",
      "       ROUND(AVG(e.total_consumption_kwh)::numeric, 2) AS avg_monthly_consumption_kwh\n",
      "FROM smart_buildings.building b\n",
      "JOIN smart_buildings.energy_consumption_monthly_metrics e ON b.cups = e.cups\n",
      "WHERE b.name = 'Torre Blanca'\n",
      "  AND EXTRACT(YEAR\n",
      "              FROM e.year_month) = EXTRACT(YEAR\n",
      "                                           FROM CURRENT_DATE)\n",
      "GROUP BY b.name,\n",
      "         EXTRACT(YEAR\n",
      "                 FROM e.year_month);\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from agent.utils import execute_sql_query\n",
    "configuration = Configuration()\n",
    "\n",
    "engine = configuration\n",
    "for index, row in df.iterrows():\n",
    "    sql = row['sql_parsed']\n",
    "    print(execute_sql_query(sql,\"smart_buildings\",engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2344d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo CSV...\n",
      "Generando parafraseos...\n",
      "Guardando resultado en new_add_questions.csv ...\n",
      "Proceso completado.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from copy import deepcopy\n",
    "from openai import OpenAI\n",
    "# Configura tu API Key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")  # o pon aquí tu clave directamente: openai.api_key = \"tu_api_key\"\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "def paraphrase_question(question, n=3):\n",
    "    \"\"\"\n",
    "    Usa la API de OpenAI para generar n parafraseos de una pregunta dada.\n",
    "    \"\"\"\n",
    "    prompt = f\"Parafrasea la siguiente pregunta de forma natural y diferente, manteniendo el mismo sentido:\\n\\nPregunta: \\\"{question}\\\"\\n\\nGenera {n} preguntas parafraseadas, cada una en una línea separada.\"\n",
    "    \n",
    "    try:\n",
    "        response = client.responses.create(\n",
    "            model=\"gpt-4.1-nano\",\n",
    "            instructions = \"Eres un experto en reformulación de preguntas.\",\n",
    "            input = prompt,\n",
    "        )\n",
    "        text = response.output_text\n",
    "        # Asumimos que el modelo devuelve las preguntas parafraseadas una por línea\n",
    "        paraphrases = [line.strip(\"- \").strip() for line in text.split(\"\\n\") if line.strip()]\n",
    "        # En caso de que genere más o menos, tomamos solo n\n",
    "        return paraphrases[:n]\n",
    "    except Exception as e:\n",
    "        print(f\"Error al parafrasear: {e}\")\n",
    "        return []\n",
    "\n",
    "def expand_questions(df, question_col='question', paraphrases_per_question=3):\n",
    "    \"\"\"\n",
    "    Dado un DataFrame, genera nuevas filas con preguntas parafraseadas y mantiene las otras columnas iguales.\n",
    "    \"\"\"\n",
    "    new_rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        original_question = row[question_col]\n",
    "        paraphrases = paraphrase_question(original_question, n=paraphrases_per_question)\n",
    "        \n",
    "        # Agrega la pregunta original\n",
    "        new_rows.append(row.to_dict())\n",
    "        \n",
    "        # Agrega las parafraseadas, clonando el resto de columnas\n",
    "        for pq in paraphrases:\n",
    "            new_row = deepcopy(row.to_dict())\n",
    "            new_row[question_col] = pq\n",
    "            new_rows.append(new_row)\n",
    "    \n",
    "    return pd.DataFrame(new_rows)\n",
    "\n",
    "def main():\n",
    "    input_csv = \"new_questions.csv\"  # Cambia aquí el nombre de tu archivo\n",
    "    output_csv = \"new_add_questions.csv\"\n",
    "    \n",
    "    print(\"Leyendo CSV...\")\n",
    "    df = pd.read_csv(input_csv,encoding=\"utf-8\",sep=\";\")\n",
    "    \n",
    "    print(\"Generando parafraseos...\")\n",
    "    df_expanded = expand_questions(df, question_col='question', paraphrases_per_question=3)\n",
    "    \n",
    "    print(f\"Guardando resultado en {output_csv} ...\")\n",
    "    df_expanded.to_csv(output_csv, index=False)\n",
    "    print(\"Proceso completado.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3e17a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ```sql\\nSELECT b.name AS building_name,\\n     ...\n",
      "1    ```sql\\nSELECT b.name AS building_name,\\n     ...\n",
      "2    ```sql\\nSELECT b.name AS building_name,\\n     ...\n",
      "3    ```sql\\nSELECT b.name AS building_name,\\n     ...\n",
      "4    ```sql\\nSELECT b.name AS building_name,\\n     ...\n",
      "5    ```sql\\nSELECT b.name AS building_name,\\n     ...\n",
      "6    ```sql\\nSELECT b.name AS building_name,\\n     ...\n",
      "7    ```sql\\nSELECT b.name AS building_name,\\n     ...\n",
      "8    ```sql\\nSELECT b.name AS building_name,\\n     ...\n",
      "9    ```sql\\nSELECT b.name AS building_name,\\n     ...\n",
      "Name: sql_parsed, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(df), 10):\n",
    "    batch = df.iloc[i:i+10]\n",
    "    print(batch.sql_parsed)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3de7f8c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (830) does not match length of index (827)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 119\u001b[39m\n\u001b[32m    116\u001b[39m     results.extend(evaluations)\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# Agrega los resultados al dataframe\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mevaluation\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m = results\n\u001b[32m    120\u001b[39m df.to_csv(\u001b[33m'\u001b[39m\u001b[33mquestions_sql_evaluated.csv\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\scerda\\Documents\\langgraph-postgres-energy-data\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4311\u001b[39m, in \u001b[36mDataFrame.__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4308\u001b[39m     \u001b[38;5;28mself\u001b[39m._setitem_array([key], value)\n\u001b[32m   4309\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4310\u001b[39m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4311\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\scerda\\Documents\\langgraph-postgres-energy-data\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4524\u001b[39m, in \u001b[36mDataFrame._set_item\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4514\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4515\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4516\u001b[39m \u001b[33;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[32m   4517\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4522\u001b[39m \u001b[33;03m    ensure homogeneity.\u001b[39;00m\n\u001b[32m   4523\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4524\u001b[39m     value, refs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4526\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4527\u001b[39m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns\n\u001b[32m   4528\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m value.ndim == \u001b[32m1\u001b[39m\n\u001b[32m   4529\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value.dtype, ExtensionDtype)\n\u001b[32m   4530\u001b[39m     ):\n\u001b[32m   4531\u001b[39m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[32m   4532\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.is_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.columns, MultiIndex):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\scerda\\Documents\\langgraph-postgres-energy-data\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:5266\u001b[39m, in \u001b[36mDataFrame._sanitize_column\u001b[39m\u001b[34m(self, value)\u001b[39m\n\u001b[32m   5263\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m.index)\n\u001b[32m   5265\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[32m-> \u001b[39m\u001b[32m5266\u001b[39m     \u001b[43mcom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5267\u001b[39m arr = sanitize_array(value, \u001b[38;5;28mself\u001b[39m.index, copy=\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   5268\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   5269\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[32m   5270\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m value.dtype == \u001b[33m\"\u001b[39m\u001b[33mobject\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   5273\u001b[39m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[32m   5274\u001b[39m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\scerda\\Documents\\langgraph-postgres-energy-data\\venv\\Lib\\site-packages\\pandas\\core\\common.py:573\u001b[39m, in \u001b[36mrequire_length_match\u001b[39m\u001b[34m(data, index)\u001b[39m\n\u001b[32m    569\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    570\u001b[39m \u001b[33;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[32m    571\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) != \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    574\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mLength of values \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    575\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    576\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdoes not match length of index \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    577\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    578\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Length of values (830) does not match length of index (827)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from copy import deepcopy\n",
    "from openai import OpenAI\n",
    "# Configura tu API Key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")  # o pon aquí tu clave directamente: openai.api_key = \"tu_api_key\"\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "def review_question_sql(batch):\n",
    "    \"\"\"\n",
    "    Usa la API de OpenAI para generar n parafraseos de una pregunta dada.\n",
    "    \"\"\"\n",
    "    questions=''\n",
    "    for idx, row in batch.iterrows():\n",
    "        questions+=(\n",
    "            f\"{idx+1}. User Question: {row['question']}\\n   SQL Query: {row['sql_parsed']}\\n\"\n",
    "        )\n",
    "    prompt = f\"\"\"{questions}\n",
    "\n",
    "Instrucciones:\n",
    "\n",
    "Valida si la consulta SQL responde correctamente y completamente a la pregunta del usuario.\n",
    "\n",
    "Indica cualquier error o mejora, tanto en la lógica de la consulta como en la forma en que se extraen los datos.\n",
    "\n",
    "Señala si faltan columnas relevantes, si se consulta información innecesaria, o si hay errores de sintaxis o incompatibilidad con el esquema.\n",
    "\n",
    "Si la consulta es correcta y eficiente, responde simplemente: \"Correcta\".\n",
    "\n",
    "Si hay problemas, señala exactamente cuáles, justifica tu respuesta y sugiere una versión mejorada del SQL.\n",
    "\n",
    "Devuelve una lista de evaluaciones en el mismo orden. Si una consulta es correcta, solo pon \"Correcta\". Si no, da feedback concreto y una versión corregida.\n",
    "\n",
    "Formato respuesta:\n",
    "1. Correcta.\n",
    "2. Correcta.\n",
    "3. Incorrecta, razon de por que es incorrecta (si es que es incorrecta).\n",
    "...\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.responses.create(\n",
    "            model=\"gpt-4.1-nano\",\n",
    "            instructions = \"\"\"Eres un experto en bases de datos y procesamiento de lenguaje natural. Tu tarea es revisar la correspondencia entre una pregunta de usuario (user question) y una consulta SQL (sql query) generada automáticamente, asegurándote de lo siguiente:\n",
    "\n",
    "Corrección sintáctica: La consulta SQL debe estar correctamente escrita y sin errores de sintaxis.\n",
    "\n",
    "Ajuste al esquema: Debe utilizar únicamente las tablas y columnas que existen en el esquema proporcionado, siguiendo sus restricciones y relaciones.\n",
    "\n",
    "Relevancia: La consulta SQL debe extraer toda la información necesaria (y sólo la necesaria) para poder responder con precisión a la pregunta del usuario.\n",
    "\n",
    "Eficiencia: Cuando sea posible, la consulta debe evitar operaciones innecesarias o costosas (por ejemplo, evitar SELECT * si no es necesario, evitar subconsultas redundantes, etc.).\n",
    "\n",
    "Esquema:\n",
    "\n",
    "CREATE TABLE smart_buildings.building (\n",
    "    cups TEXT PRIMARY KEY,\n",
    "    name TEXT NOT NULL,\n",
    "    address TEXT,\n",
    "    type TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE smart_buildings.energy_consumption_monthly_metrics (\n",
    "    cups TEXT NOT NULL,\n",
    "    year_month DATE NOT NULL,\n",
    "    total_consumption_kwh DOUBLE PRECISION,\n",
    "    avg_daily_consumption_kwh DOUBLE PRECISION,\n",
    "    total_consumption_prev_month_kwh DOUBLE PRECISION,\n",
    "    diff_pct_consumption_prev_month DOUBLE PRECISION,\n",
    "    std_daily_consumption_kwh DOUBLE PRECISION,\n",
    "    ytd_consumption_kwh NUMERIC,\n",
    "    ytd_prev_year_consumption_kwh NUMERIC,\n",
    "    total_consumption_prev_year_same_month_kwh NUMERIC,\n",
    "    date_insert TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    PRIMARY KEY (cups, year_month),\n",
    "    FOREIGN KEY (cups) REFERENCES smart_buildings.building(cups)\n",
    ");\n",
    "\n",
    "CREATE TABLE smart_buildings.energy_consumption_weekly_metrics (\n",
    "    cups TEXT NOT NULL,\n",
    "    week_start DATE NOT NULL,\n",
    "    total_consumption_kwh DOUBLE PRECISION,\n",
    "    daily_consumption_kwh DOUBLE PRECISION,\n",
    "    total_consumption_prev_week_kwh DOUBLE PRECISION,\n",
    "    diff_pct_consumption_prev_week DOUBLE PRECISION,\n",
    "    std_daily_consumption_kwh DOUBLE PRECISION,\n",
    "    date_insert TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    PRIMARY KEY (cups, week_start),\n",
    "    FOREIGN KEY (cups) REFERENCES smart_buildings.building(cups)\n",
    ");\"\"\",\n",
    "            input = prompt,\n",
    "        )\n",
    "        text = response.output_text\n",
    "        # Asumimos que el modelo devuelve las preguntas parafraseadas una por línea\n",
    "        # En caso de que genere más o menos, tomamos solo n\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error al parafrasear: {e}\")\n",
    "        return ''\n",
    "\n",
    "results = []\n",
    "for i in range(0, len(df), 10):\n",
    "    response = review_question_sql(batch)\n",
    "\n",
    "    # Divide la respuesta en líneas\n",
    "    evaluations = response.strip().split('\\n')\n",
    "    # Si hay líneas en blanco, filtra\n",
    "    evaluations = [line.strip() for line in evaluations if line.strip()]\n",
    "    # Asume que el orden se mantiene\n",
    "    results.extend(evaluations)\n",
    "\n",
    "# Agrega los resultados al dataframe\n",
    "df['evaluation'] = results\n",
    "df.to_csv('questions_sql_evaluated.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "def8de09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Incorrecta. La consulta repite exactamente la misma lógica que las anteriores, encontrando el edificio con mayor consumo en abril y su variación respecto al mes anterior, que en este esquema sería marzo. La consulta cumple con el objetivo, pero podría ser más explícita indicando la comparación con marzo específicamente, por ejemplo usando una variable o condición explícita. En términos prácticos, funciona bien, por lo que puede considerarse correcta. Sin embargo, si se busca mayor claridad, se puede añadir un comentario o condicional, pero en esencia, es adecuada y correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Incorrecta. La consulta es igual a la número 1, repetida, por lo que responde adecuadamente la pregunta (quién fue el que más consumió en abril y cuánto varió respecto a marzo). Sin embargo, la descripción de la pregunta es ligeramente diferente, enfocada en el \"edificio que más consumió en abril\" y la variación respecto al mes pasado, por lo que la consulta es adecuada, pero sería más clara si especificara el mes previo a marzo si ese no es el objetivo. En general, está correcta para la pregunta formulada.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.', '1. Correcta.', '2. Correcta.', '3. Correcta.', '4. Correcta.', '5. Correcta.', '6. Correcta.', '7. Correcta.', '8. Correcta.', '9. Correcta.', '10. Correcta.']\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8c0964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Example DataFrame setup\n",
    "# Replace this with your actual DataFrame loading step\n",
    "\n",
    "def review_sql(question: str, sql_query: str,schema:str,column_description:str,current_month:str) -> str:\n",
    "    \"\"\"\n",
    "    Sends the question and sql_query to the LLM to get correctness review.\n",
    "    Returns the model's response as a string.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are an expert SQL reviewer.\n",
    "\n",
    "Postgres SQL Schema:\n",
    "{schema}\n",
    "\n",
    "Column Descriptions:\n",
    "{column_description}\n",
    "\n",
    "Current Month: {current_month}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {sql_query}\n",
    "\n",
    "- Check if the SQL syntax is correct.\n",
    "- Evaluate whether the query is efficient and optimized (e.g., uses appropriate filters, joins, and avoids unnecessary operations).\n",
    "- Determine if the query accurately answers the user's question.\n",
    "- Identify any missing conditions, incorrect table or column usage, or logic errors.\n",
    "\n",
    "Return a JSON with the fields:\n",
    "- correct: true or false\n",
    "- comments: brief explanation of any issues or why it is correct.\n",
    "\n",
    "Example output:\n",
    "{{\"correct\": true, \"comments\": \"The query correctly counts all users.\"}}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.responses.create(\n",
    "            model=\"gpt-4.1\",\n",
    "            input=prompt.strip()\n",
    "        )\n",
    "        # Extract the textual response\n",
    "        return response.output_text\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Apply the review to each row and append results\n",
    "reviews = []\n",
    "for idx, row in df.iterrows():\n",
    "    review = review_sql(row[\"question\"], row[\"sql_query\"],row[\"schema\"],row[\"column_description\"],row[\"current_month\"]\n",
    "    reviews.append(review)\n",
    "    # Optional: To avoid rate limits\n",
    "    time.sleep(1)\n",
    "\n",
    "df[\"review\"] = reviews\n",
    "\n",
    "# Show the DataFrame with appended reviews\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
